import streamlit as st
import requests
import os

# -----------------------------
# CONFIGURATION DE LA PAGE
# -----------------------------
st.set_page_config(
    page_title="Tuteur √âducatif Personnalis√© (LLM)",
    page_icon="üéì",
    layout="centered"
)

st.title("üéì Tuteur √âducatif Personnalis√©")
st.write(
    "Ce tuteur utilise un **Large Language Model (LLM)** pour accompagner "
    "les √©tudiants de **Licence 3 Informatique** de mani√®re personnalis√©e."
)

# -----------------------------
# PARAM√àTRES UTILISATEUR
# -----------------------------
matiere = st.selectbox(
    "üìò Choisissez la mati√®re :",
    ["Programmation Python", "Algorithmique et structures de donn√©es"]
)

niveau = st.selectbox(
    "üéØ Choisissez votre niveau :",
    ["D√©butant", "Interm√©diaire", "Avanc√©"]
)

question = st.text_area(
    "‚úèÔ∏è Posez votre question :",
    placeholder="Ex : Explique-moi les boucles en Python"
)

# -----------------------------
# CL√â API HUGGING FACE
# -----------------------------
HF_API_TOKEN = os.getenv("HF_API_TOKEN")

API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2"
headers = {
    "Authorization": f"Bearer {HF_API_TOKEN}"
}

# -----------------------------
# FONCTION D'APPEL AU LLM
# -----------------------------
def appeler_llm(prompt):
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 500,
            "temperature": 0.7
        }
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# -----------------------------
# BOUTON DE G√âN√âRATION
# -----------------------------
if st.button("üì§ Obtenir l'explication"):

    if not HF_API_TOKEN:
        st.error("‚ùå Cl√© API Hugging Face manquante.")
    elif question.strip() == "":
        st.warning("‚ö†Ô∏è Veuillez entrer une question.")
    else:
        prompt = f"""
Tu es un tuteur √©ducatif universitaire pour un √©tudiant en Licence 3 Informatique.

Mati√®re : {matiere}
Niveau de l'√©tudiant : {niveau}

R√®gles p√©dagogiques :
- Adapter le langage au niveau
- Expliquer progressivement
- Donner des exemples clairs
- Encourager l'√©tudiant
- Poser une question √† la fin pour v√©rifier la compr√©hension

Question de l'√©tudiant :
{question}
"""

        with st.spinner("‚è≥ G√©n√©ration de la r√©ponse p√©dagogique..."):
            resultat = appeler_llm(prompt)

                # -----------------------------
        # GESTION DES R√âPONSES API
        # -----------------------------
        if isinstance(resultat, list):
            st.success("‚úÖ R√©ponse du tuteur")
            st.write(resultat[0]["generated_text"])

        elif isinstance(resultat, dict) and "error" in resultat:
            if "loading" in resultat["error"].lower():
                st.warning(
                    "‚è≥ Le mod√®le est en cours de chargement. "
                    "Veuillez r√©essayer dans quelques secondes."
                )
            else:
                st.error(f"‚ùå Erreur du mod√®le : {resultat['error']}")

        else:
            st.error("‚ùå R√©ponse inattendue de l‚ÄôAPI Hugging Face.")

